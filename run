#!/bin/bash
# Builds one or more datasets from original sources, resulting in data and
# torrent files.
#
# This script manages data inventory and checks for new revisions of things. All
# of these checks are done through the docker image.

set +euo pipefail

original_pwd=$PWD
cd "$(dirname "$0")"

# Always run ni from inside the docker.
ni() { docker run --rm spencertipping/academictorrents ni "$@"; }


# Dataset age checking
# Functions that return the latest revision of any given dataset. You'll use
# these arguments to specify which revision you want to build, and output
# directories also take these names.

strm1_latest() { echo original; }

osm_planet_latest() {
  ni https://planet.openstreetmap.org/planet/ \
     r/planet-latest/ p'join"", /(20..)-(..)-(..)/' r1
}

wikipedia_history_latest() {
  ni https://dumps.wikimedia.org/enwiki/ p'/href="([^"\/]+)\/?"/' r+2r1
}

wikipedia_pages_latest() { wikipedia_history_latest; }


# Dataset function delegates
# Specify the list of datasets we have available. Then we can build full version
# lists and manage multi-dataset processing.

declare -a datasets
defdataset() {
  datasets+=( "$1" )
  eval "$1() {
    method=\$1
    shift
    ${1}_\$method \"\$@\"
  }"
}


defdataset strm1
defdataset osm_planet
defdataset wikipedia_history
defdataset wikipedia_pages


# Repository configuration
: ${ACADEMICTORRENTS_DATA:=/tmp}
: ${ACADEMICTORRENTS_TMP:=/tmp}

mb_free_in() { df -m "$1" | tail -n1 | awk '{print $4}'; }


# Main argument processing
cmd=$1
shift
case $cmd in
  config)
    data_free_gb=$(( $(mb_free_in "$ACADEMICTORRENTS_DATA") / 1024 ))
    tmp_free_gb=$((  $(mb_free_in "$ACADEMICTORRENTS_TMP")  / 1024 ))

    echo "ACADEMICTORRENTS_DATA = $ACADEMICTORRENTS_DATA [$data_free_gb GiB free]"
    echo "ACADEMICTORRENTS_TMP  = $ACADEMICTORRENTS_TMP [$tmp_free_gb GiB free]"

    if [[ "$ACADEMICTORRENTS_DATA" == /tmp ]]; then
      echo
      echo "You don't have a data repository configured yet, so we're using /tmp."
      echo "To set one up:"
      echo "  $ mkdir -p /path/to/data"
      echo "  $ export ACADEMICTORRENTS_DATA=/path/to/data"
      echo
    fi
    ;;

  docker)
    cmd=$1
    shift
    case $cmd in
      build) docker/build ;;
      pull)  docker pull spencertipping/academictorrents ;;
      shell) docker run --rm -v "$original_pwd:/process" \
                    -it spencertipping/academictorrents \
                          sh -c 'cd /process; exec /bin/bash' ;;

      *)
        echo "usage:"
        echo "  $0 docker build"
        echo "  $0 docker pull"
        echo "  $0 docker shell"
        echo
        exit 1
        ;;
    esac
    ;;

  datasets)
    IFS=$'\n'
    echo "${datasets[*]}" | sort
    ;;

  latest)
    for d in "${datasets[@]}"; do
      echo -e "$d\t$($d latest)"
    done
    ;;

  *)
    for d in "${datasets[@]}"; do
      if [[ "$cmd" == "$d" ]]; then
        "$cmd" "$@"
        exit $?
      fi
    done

    echo "usage: $0 command [args...]"
    echo ""
    echo "available commands:"
    echo "  config                  show configuration variables"
    echo "  docker ...              commands related to docker image"
    echo "  datasets                list datasets"
    echo "  [dataset_name] ...      manipulate one dataset"
    echo "  latest                  get latest version of each dataset"
    echo
    exit 1
    ;;
esac
