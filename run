#!/bin/bash
# Builds one or more datasets from original sources, resulting in data and
# torrent files.
#
# This script manages data inventory and checks for new revisions of things. All
# of these checks are done through the docker image.

set +euo pipefail

original_pwd=$PWD
cd "$(dirname "$0")"

docker_build() { docker/build; }
docker_pull()  { docker pull spencertipping/academictorrents; }

# Always run ni from inside the docker.
ni() { docker run --rm spencertipping/academictorrents ni "$@"; }


# Dataset age checking
# Functions that return the latest revision of any given dataset. You'll use
# these arguments to specify which revision you want to build, and output
# directories also take these names.

strm1_latest() { echo original; }

osm_planet_latest() {
  ni https://planet.openstreetmap.org/planet/ \
     r/planet-latest/ p'join"", /20(..)-(..)-(..)/' r1
}

wikipedia_history_latest() {
  ni https://dumps.wikimedia.org/enwiki/ p'/href="([^"\/]+)\/?"/' r+2r1
}

wikipedia_pages_latest() { wikipedia_history_latest; }


# Dataset function delegates
# Specify the list of datasets we have available. Then we can build full version
# lists and manage multi-dataset processing.

declare -a datasets
defdataset() {
  dataset+=( "$1" )
  eval "$1() {
    method=\$1
    shift
    ${1}_\$method \"\$@\"
  }"
}


defdataset strm1
defdataset osm_planet
defdataset wikipedia_history
defdataset wikipedia_pages


# Main argument processing
dataset_pattern="$(IFS="|"; echo "${datasets[@]}")"

cmd=$1
shift
case $cmd in
  docker) docker_commands "$@" ;;

  datasets)
    IFS=$'\n- '
    echo "available datasets:"
    echo "${datasets[@]}"
    echo
    ;;

  $dataset_pattern) "$cmd" "$@" ;;
  *)
    echo "usage: $0 command [args...]"
    echo ""
    echo "available commands:"
    echo "- docker build"
    echo "- docker pull"
    echo "- datasets"
    echo "- [dataset_name] ..."
    ;;
esac
